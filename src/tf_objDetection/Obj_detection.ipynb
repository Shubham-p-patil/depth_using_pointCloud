{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport os\nimport six.moves.urllib as urllib\nimport sys\nimport tarfile\nimport tensorflow as tf\nimport zipfile\n\nfrom collections import defaultdict\nfrom io import StringIO\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\n# This is needed since the notebook is stored in the object_detection folder.\nsys.path.append(\"models/research/\")\nsys.path.append(\"models/research/object_detection\")\n\nfrom object_detection.utils import ops as utils_ops"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# This is needed to display the images.\n%matplotlib inline\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from utils import label_map_util\n\nfrom utils import visualization_utils as vis_util"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# What model to download.# What  \n\nMODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'\n\n# Path to frozen detection graph. This is the actual model that is used for the object detection.\nPATH_TO_CKPT = os.path.join(os.getcwd(),'models/research/object_detection',MODEL_NAME ,'frozen_inference_graph.pb')\nprint(os.path)\n\n# List of the strings that is used to add correct label for each box.\nPATH_TO_LABELS = os.path.join(os.getcwd(),'models/research/object_detection','data', 'mscoco_label_map.pbtxt')\nprint(os.path)\n\nNUM_CLASSES = 90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "detection_graph = tf.Graph()\nwith detection_graph.as_default():\n  od_graph_def = tf.GraphDef()\n  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n    serialized_graph = fid.read()\n    od_graph_def.ParseFromString(serialized_graph)\n    tf.import_graph_def(od_graph_def, name='')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\ncategory_index = label_map_util.create_category_index(categories)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import cv2\ncap=cv2.VideoCapture(0) # 0 stands for very first webcam attach\n\ndetection_graph.as_default()\nsess = tf.Session(graph=detection_graph)\nwhile True:\n    ret, image_np = cap.read()\n    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n    image_np_expanded = np.expand_dims(image_np, axis=0)\n#         print image_np_expanded\n    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n#         print image_tensor\n\n    # Each box represents a part of the image where a particular object was detected.\n    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n\n    # Each score represent how level of confidence for each of the objects.\n    # Score is shown on the result image, together with the class label.\n    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n\n    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n\n    # Actual detection.\n    (boxes, scores, classes, num_detections) = sess.run(\n      [boxes, scores, classes, num_detections],\n      feed_dict={image_tensor: image_np_expanded})\n    #         print num_detections\n    boxes = np.squeeze(boxes)\n    classes= np.squeeze(classes)\n    scores = np.squeeze(scores)\n\n    #         print classes\n    max_boxes_to_draw = 20\n    display_str = ''\n    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n        if scores[i]>0.5:\n            box = tuple(boxes[i].tolist())\n            if classes[i] in category_index.keys():\n                class_name = category_index[classes[i]]['name']\n            else:\n                class_name = 'N/A'\n            display_str = str(class_name)\n        print \"Dedicated Object\"\n        print display_str\n        print box\n\n    # Visualization of the results of a detection.\n    vis_util.visualize_boxes_and_labels_on_image_array(image_np,\n        np.squeeze(boxes),\n        np.squeeze(classes).astype(np.int32),\n        np.squeeze(scores),\n        category_index,                         \n        use_normalized_coordinates=True,\n        line_thickness=8)\n\n    cv2.imshow('object detection', cv2.resize(image_np, (800,600)))\n    if cv2.waitKey(25)& 0xFF == ord('q'):\n        cv2.destroyAllWindows()\n        cap.release()\n        break"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cap.release()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
